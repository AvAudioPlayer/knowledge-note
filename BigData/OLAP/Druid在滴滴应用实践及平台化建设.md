# OLAP 数据库引擎 Druid 在滴滴应用实践及平台化建设是怎样的？

[原文链接](https://mp.weixin.qq.com/s/ByDu4XPy-xbdtefgI6w5dQ)

**摘要：**

Druid 是一款支持数据实时写入、低延时、高性能的 OLAP 引擎，具有优秀的数据聚合能力与实时查询能力。在大数据分析、实时计算、监控等领域都有特定的应用场景，是大数据基础架构建设中重要的一环。Druid 在滴滴承接了包括实时报表、监控、数据分析、大盘展示等应用场景的大量业务，作为大数据基础设施服务于公司多条业务线。本次演讲我们将介绍 Druid 的核心特性与原理，以及在滴滴内部大规模使用中积累的经验。

**分享大纲：**

[一、Druid 特性简介](#一、Druid 特性简介)
2、Druid 在滴滴的应用
3、Druid 平台化建设
4、展望

# 一、Druid 特性简介

Druid 是针对时间序列数据提供的低延时数据写入以及快速交互式查询的分布式 OLAP 数据库。其两大关键点是：首先，Druid 主要针对时间序列数据提供低延时数据写入和快速聚合查询; 其次，Druid 是一款分布式 OLAP 引擎。
　　
针对第一个特点来看，Druid 与典型的 TSDB，比如 InfluxDB、Graphite、OpenTSDB 的部分特性类似。这些时序数据库具备一些共同特点，一是写入即可查，通过内存增量索引让数据写入便可查询; 二是下采样或 RDD，通过下采样或类似于 RDD 的操作减少数据量，而 Druid 在数据写入时就会对数据预聚合，进而减少原始数据量，节省存储空间并提升查询效率; 三是可能会支持 Schema less，在 InfluxDB 中，用户可任意增加 tag，InfluxDB 可对新增 tag 进行聚合查询，但 Druid 在这点上与 InfluxDB 略有差异，Druid 需要预先定义 Schema 。Druid 的 Schema 数据打包在最后形成的数据文件中，数据文件按照时间分片，也就是说过去和未来数据的 Schema 可以不同，而不同 schema 的数据可以共存。所以，虽然 Druid 不是 schema less 的，但是 Schema 调整也是比较灵活。
　　
另外，Druid 作为一个 OLAP 数据库。OLAP 数据库需要支持类似上卷、切块、切片、下钻等操作，但不适合明细查询。对于类似根据某主键 ID 定位唯一数据的任务，OLAP 数据库并不能友好支持。常用的 OLAP 数据库实现方式以下几种：1) 数据检索引擎，比如 ES;2) 预计算加 KV 存储实现，比如 Kylin;3)SQL on Hadoop 引擎，比如 Presto、SparkSQL。
　　
接下来，我们就以上中实现进行对比。首先是数据检索引擎的代表 ES，ES 可以存储结构化和非结构化数据，同时具备明细查询和聚合查询能力，由于其自身是一个数据检索引擎，其索引类型并不是针对聚合分析设计的，所以聚合查询方面开销较大; 其次，ES 不但要保存所有的原始数据，还需要生成较多的索引，所以存储空间开销会更大，数据的写入效率方面会比 Druid 差一些。
　　
与 ES 相比，Druid 只能处理结构化数据，因为它必须预定义 Schema; 其次，Druid 会对数据进行预聚合以减少存储空间，同时对数据写入和聚合进行优化。但是，由于进行了预聚合，所以 Druid 抛弃掉了原始数据，导致其缺少原始明细数据查询能力。如果业务方有需求，可以关闭预聚合，但会丧失 Druid 的优势。
　　
其次是预计算 + kv 存储方式 ，KV 存储需要通过预计算实现聚合，可以认为 Key 涵盖了查询参数，而值就是查询结果，由于直接从 KV 存储进行查询，所以速度非常快。缺点是因为需要在预计算中处理预设的聚合逻辑，所以损失了查询灵活性，复杂场景下的预计算过程可能会非常耗时，而且面临数据过于膨胀的情况; 由于只有前缀拼配一种索引方式，所以在大数据量的复杂过滤条件下，性能下降明显; 且缺少聚合下推能力。
　　
与预计算 + KV 存储方式相比，Druid 是使用 Bitmap 索引的列式存储，查询速度肯定不如 KV 存储快; 但是由于使用内存增量索引，增量预聚合的模式，写入即可查，无需等待预计算生成 Cube，所以实时性更强; 其次，Druid 可针对任意维度组合过滤、聚合，查询更加灵活; 最后，Scatter & Gather 模式支持一定的聚合下推。
　　
最后是 SQL on Hadoop， 这类引擎的 SQL 支持通常很强大，且无冗余数据，不需要预处理。缺点是因为其直接通过计算引擎对 Hadoop 上的文件进行操作，所以响应速度较慢且 QPS 相对较低。
　　
与 SQL on Hadoop 方式相比，Druid 的 SQL 支持有限，但在逐渐完善; 必须预定义维度指标。其优势在于可达到亚秒级响应，并发较高。

# 二、Durid 在滴滴的应用
Druid 目前在滴滴使用规模大概为多个集群百余台机器，日原始数据写入量在千亿级别，日落盘数据在 TB 级别，数百实时数据源、千级实时写入任务，日查询量近千万级。主要承接业务有监控、实时报表，大屏展示等。
　　
下图为滴滴实时业务监控案例：
![](/assets/Durid 在滴滴的应用_图2-1.jpg)

我们的监控体系大概可以分为三层：顶层为业务监控，主要由业务方定义指标，然后配置相应的查询和报警。主要目的在于及时发现业务问题并告警; 中层的监控体系是对各服务网关调用的监控日志，主要为了发现某业务问题造成的影响范围和具体影响对象; 底层运维体系主要对网络、机器各方面指标进行监控。
　　
之所以业务监控适用 Druid，是因为业务指标通常具有较为复杂多变的业务逻辑。Druid 本身是一个 OLAP 引擎，定义一个数据源就可衍生出众多聚合指标，所以很适合这类灵活查询的配置。
　　
第二类应用是实时报表类应用 (如下图)，实时报表类应用主要用于运营数据分析，客户端网络性能分析以及客服应答实时统计等。这些用户通常是从 Hive 数据仓库迁移过来的，因为希望获得实时用户体验而 Hive 查询速度太慢，所以选择迁移。典型应用场景比如快速获取某下雨区域的用户单据，对用户进行优惠券投放进而刺激用户打车。
![](/assets/Durid 在滴滴的应用_图2-2.jpg)

第三类是大屏展示类应用 (如下图)，这类应用主要用于呈现业务性关键结果，通常是 PV、UV 或 TOP N 查询，非常适合 Druid。
![](/assets/Durid 在滴滴的应用_图2-3.jpg)

# 三、Druid 平台化建设

在承接应用场景的过程中，我们做了很多平台化建设。简单啊介绍下平台化建设的背景： 业务数据主要来源是日志和 binlog; 公司统一数据通道是 kafka; 业务指标多样，逻辑复杂多变; Druid 接入配置较复杂，除 Schema 配置外，还包括实时任务配置; 数据进入 Druid 之前通常需要流计算处理，业务方自己开发既费时又很容易出现问题; Druid 数据的对应关系以及数据源衍生指标链路较长，需要进行上下游关系梳理; 由于 Druid 官方主要通过 API 查询，未提供数据可视化服务组件，因此业务方急需数据可视化相关服务组件。
　　
在以上的背景下，我们构建了实时计算平台，架构图如下：
![](/assets/Druid 在滴滴应用_图3-1.jpg)

