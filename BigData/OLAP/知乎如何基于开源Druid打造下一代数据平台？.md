# 知乎如何基于开源Druid打造下一代数据平台？

![](/assets/知乎如何基于开源Druid打造下一代数据平台_图1-1.jpg)

## 背景

知乎作为知名中文知识内容平台，业务增长和产品迭代速度很快，如何满足业务快速扩张中的灵活分析需求，是知乎数据平台组要面临的一大挑战。
知乎数据平台团队基于开源的 Druid 打造的业务自助式的数据分析平台，经过研发迭代，目前支撑了全业务的数据分析需求，是业务数据分析的重要工具。
目前，平台主要的能力如下：

统一的数据源管理，支持摄入离线数仓的 Hive 表和实时数仓的 Kafka 流
自助式报表配置，支持多维分析报表、留存分析报表
灵活的多维度多指标的组合分析，秒级响应速度，支持嵌套式「与」和「或」条件筛选
自助式仪表盘配置
开发平台接口，为其他系统提供数据服务
统一的数据权限管理
目前，业务使用平台的数据如下：
自助式配置仪表盘数：495 个，仪表盘内报表共计：2399 张
日请求量 3w+
为 A/B Testing、渠道管理、APM 、数据邮件等系统提供数据 API

## 数据分析平台架构

![](/assets/知乎如何基于开源Druid打造下一代数据平台_图1-2.jpg)

### 技术选型 - Druid

Druid 是一种能对历史和实时数据提供亚秒级别的查询的数据存储。
Druid 支持低延时的数据摄取，灵活的数据探索分析，高性能的数据聚合，简便的水平扩展。适用于数据量大，可扩展能力要求高的分析型查询系统。
![](/assets/知乎如何基于开源Druid打造下一代数据平台_图1-3.jpg)

#### Druid 数据结构和架构简介

**Druid 数据结构**
* DataSource：Druid 的基本数据结构，在逻辑上可以理解为关系型数据库中的表。它包含时间、维度和指标三列。
* Segment：Druid 用来存储索引的数据格式，不同的索引按照时间跨度来分区，分区可通过 segmentGranularity（划分索引的时间粒度）进行配置。

**查询服务的相关组件**
内部组件
* Historical：用于加载和提供 Segment 文件供数据查询。
* Broker：提供数据查询服务，通过路由查询请求到对应的 Historical 节点并获得数据，合并数据后返回给调用方。
* Router：当 Druid 集群到达 TB 级别的规模时才需要启用的节点，主要负责将查询请求路由到不同的 Broker 节点上。

外部组件
* Deep Storage：用于存储 Segment 文件供 Historical 节点下载。Deep Storage 不属于 Druid 内部组件，用户可根据系统规模来自定义配置。单节点可用本地磁盘，分布式可用 HDFS。
* Metastore Storage：用于存储 Druid 的各种元数据信息，属于 Druid 的外部依赖组件，生产环境中可用 MySQL。
